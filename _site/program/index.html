<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Program</title>
  <meta name="description" content="The Asian CHI Symposium showcases the latest work from Asia on interactive systems and user interfaces that address under-explored problems and showcase uniq...">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Signika">
  <link rel="stylesheet" href="/2020/assets/main.css">
  <link rel="stylesheet" href="/2020/assets/css/academicons.min.css"/>
  <link rel="canonical" href="http://localhost:4000/2020/program/">
  <link rel="alternate" type="application/rss+xml" title="Asian CHI Symposium 2020" href="/2020/feed.xml">
  <link rel="icon" type="image/png" href="/2020/assets/favicon.png">
  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>

  <script defer src="https://use.fontawesome.com/releases/v5.6.3/js/all.js" integrity="sha384-EIHISlAOj4zgYieurP0SdoiBYfGJKkgWedPHH4jCzpCXLmzVsw1ouK59MuUtP4a1" crossorigin="anonymous"></script>
  
  
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
   

  

  <!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Program | Asian CHI Symposium 2020</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Program" />
<meta name="author" content="Asian CHI Symposium" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Asian CHI Symposium showcases the latest work from Asia on interactive systems and user interfaces that address under-explored problems and showcase unique approaches." />
<meta property="og:description" content="The Asian CHI Symposium showcases the latest work from Asia on interactive systems and user interfaces that address under-explored problems and showcase unique approaches." />
<link rel="canonical" href="http://localhost:4000/2020/program/" />
<meta property="og:url" content="http://localhost:4000/2020/program/" />
<meta property="og:site_name" content="Asian CHI Symposium 2020" />
<script type="application/ld+json">
{"url":"http://localhost:4000/2020/program/","headline":"Program","author":{"@type":"Person","name":"Asian CHI Symposium"},"description":"The Asian CHI Symposium showcases the latest work from Asia on interactive systems and user interfaces that address under-explored problems and showcase unique approaches.","@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper header-wrapper">
    <div class="site-titles">
      <div class="site-logo-name">
        <a class="site-title" href="/2020/">Asian CHI Symposium 2020</a>
        <p class="site-subtitle">April 25, 2020, Honolulu, Hawai&#39;i, USA</p>
      </div>
      <div class="logo"></div>
    </div>
  
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
              <a href="/2020/"  class="page-link" >Home</a>
            
          
            
              <a href="/2020/call/"  class="page-link" >Call (EN)</a>
            
          
            
              <a href="/2020/call-jp/"  class="page-link" >Call (JP)</a>
            
          
            
              <a href="/2020/program/"  class="current-page" >Program</a>
            
          
            
              <a href="/2020/organizing/"  class="page-link" >Organizing</a>
            
          
            
              <a href="https://asian-chi.github.io"  class="page-link" >Past Symposia</a>
            
          
        </div>
      </nav>
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="main-title">Program</h1>
  </header>

  <div class="main-content">
    <div class="abstract">
    <h2>Date &amp; Venue</h2>
    <div class="abstract-overview">
        <ul class="sidebar-items program">
            <li>Date: April 25, 2020 (Saturday)</li>
            <li>Time: 12:00 - 18:00 JST</li>
            <li>Venue: Zoom</li>
        </ul>
    </div>
    <h2>Schedule</h2>
    
    <ul class="sidebar-items program">
        
            <li>
                <p>
                    <span class="news-date">11:40 - 12:00</span> &#187; 
                    <span class="news-text">Virtual Registration. Participants join on Skype/Zoom. Re-read instructions.</span>&nbsp;
                    
                    
                </p>
                <p class="program-note">Participants must be well informed of their schedule, and follow the instruction prepared by the organizers.</p>
            </li>
        
            <li>
                <p>
                    <span class="news-date">12:00 - 12:15</span> &#187; 
                    <span class="news-text">Opening Remarks &amp; Household Rules</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">12:15 - 13:00</span> &#187; 
                    <span class="news-text">Keynote #1:</span>&nbsp;
                    
                        <a class="program-speaker" href="http://www.shengdongzhao.com/" target="_blank">Shengdong "Shen" Zhao</a>,
                        National University of Singapore | <a href="#shen">Bio &amp; Abstract</a>
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">13:00 - 13:10</span> &#187; 
                    <span class="news-text">Group screenshots &amp; Explain online voting for original submissions</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">13:10 - 14:20</span> &#187; 
                    <span class="news-text">Parallel Session 1</span>&nbsp;
                    
                    
                        <ul class="sidebar-items program group">
                            
                            <li>
                                <p>
                                    <span class="news-date">13:10 - 14:20</span> &#187; 
                                    <span class="news-text">Group A - Interaction Techniques</span>
                                </p>
                            </li>
                            
                            <li>
                                <p>
                                    <span class="news-date">13:10 - 14:20</span> &#187; 
                                    <span class="news-text">Group B - Localized Studies</span>
                                </p>
                            </li>
                            
                        </ul>
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">14:20 - 14:30</span> &#187; 
                    <span class="news-text">Virtual coffee break &amp; Preparation for Parallel Session 2</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">14:30 - 15:40</span> &#187; 
                    <span class="news-text">Parallel Session 2</span>&nbsp;
                    
                    
                        <ul class="sidebar-items program group">
                            
                            <li>
                                <p>
                                    <span class="news-date">14:30 - 15:40</span> &#187; 
                                    <span class="news-text">Group C - Health and Self-Improvement</span>
                                </p>
                            </li>
                            
                            <li>
                                <p>
                                    <span class="news-date">14:30 - 15:40</span> &#187; 
                                    <span class="news-text">Group D - Communities and Societies</span>
                                </p>
                            </li>
                            
                        </ul>
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">15:40 - 15:50</span> &#187; 
                    <span class="news-text">CHI 2020 montage break &amp; Preparation for Parallel Session 3</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">15:50 - 17:10</span> &#187; 
                    <span class="news-text">Session 3 - Showcase</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">17:10 - 17:20</span> &#187; 
                    <span class="news-text">Past Asian CHI montage</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">17:20 - 17:35</span> &#187; 
                    <span class="news-text">Online Voting Result Announcements</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
            <li>
                <p>
                    <span class="news-date">17:35 - 17:50</span> &#187; 
                    <span class="news-text">Closing Remarks</span>&nbsp;
                    
                    
                </p>
                
            </li>
        
    </ul>
    
    <h2>Keynote Speakers</h2>
    <div class="abstract-overview">
        <ul class="sidebar-items keynote">
            
                <li>
                    <img class="keynote-photo" src="../assets/jpg/shen_zhao.jpg" />
                    <a class="keynote-speaker" href="http://www.shengdongzhao.com/" target="_blank">Shengdong Zhao</a>
                    National University of Singapore
                </li>
            
        </ul>
    </div>
    <h2 id="accepted-submissions">Accepted Submissions</h2>
    
    <ul class="sidebar-items program">
        
            <h3>Interaction Techniques</h3>
            
            <li class="accepted-submission">
                <div class="accepted-id">#8</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Water Flow Visualization for Swimming using Nanocellulose</span>
                    <p class="accepted-authors">Shogo Yamashita (The University of Tokyo)</p>
                    <p class="accepted-abstract">Fluid measurement has many significant applications in scientific and engineering research, such as evaluation of fluid simulation, design of underwater vehicles, and development of artificial hearts and engines. Fluid measurement is also an active research area in the biomechanics of water sports. In this research, we propose a potential fluid-measurement technology using nanocellulose and a harmless light source. This technology has significant contributions to biomechanics research using fluid simulation and motion analysis by providing a way to evaluate the simulation results. In this resaerch, we investigated the feasibility of the polarization-based water flow measurement technology using tracer particles with optical anisotropy. We measured water flow in a swimming environment with a swimmer.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#15</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Gaze-based Command Activation Technique using Two-level Stroke</span>
                    <p class="accepted-authors">Toshiya Isomoto (University of Tsukuba); Shota Yamanaka (Yahoo! JAPAN); Buntarou Shizuki (University of Tsukuba)</p>
                    <p class="accepted-abstract">We show a gaze-based command activation technique which uses a two-level stroke as a gesture. A two-level stroke is a simple gesture such as a horizontal then a vertical stroke or a vertical then a horizontal stroke. An object on which users want to activate a command is selected with dwell-based target selection. Thus, the command is activated by dwelling on an object and then moving the gaze to form a two-level stroke. As a result of an experiment, the success rate of command activation is 85.8% and the time taken for a command activation is 956 ms.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#52</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Grip Strength Rehabilitation Using a Monocular Camera</span>
                    <p class="accepted-authors">Nagisa Matsumoto (Keio University); Koji Fujita (Tokyo Medical and Dental University); Yuta Sugiura (Keio University)</p>
                    <p class="accepted-abstract">Hand rehabilitation recovers hand function. Grip strength exercise is one method of rehabilitation. While easy to perform, there are several problems, such as not obtaining objective feedback. Therefore, in this study, we propose a real-time measurement system for grip strength using a softball and a monocular camera. Experimental results showed the correlation between the finger joint angles estimated by an image and the air pressure of the ball when grasped and that we can estimate the grip strength from the image.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#105</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Preliminary Investigation of Tapping Force on Pressure-Sensitive Touchscreen for Expanding Input Vocabulary on Smartphone</span>
                    <p class="accepted-authors">Ryo Ikeda, Yuta Urushiyama, and Buntarou Shizuki (University of Tsukuba)</p>
                    <p class="accepted-abstract">We propose the method to expand the input vocabulary of a smartphone using tapping force on the pressure-sensitive touchscreen. In our method, the input mode is switched by users controlling multiple levels of the tapping force. To design our method, we conducted the user study to determine the optimal number of levels and these thresholds. For example, we need to determine the thresholds between first and second, second and third levels of the tapping force in 3 levels. The results showed that users may control 3 levels of the tapping force. On the other hand, the results also showed that we need to consider the user calibration to determine the threshold instead of the fixed threshold.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#110</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Expanding Input Vocabulary Using Index Finger on and Above Back of Smartphone</span>
                    <p class="accepted-authors">Yusuke Sei, Minto Funakoshi, and Buntarou Shizuki (University of Tsukuba)</p>
                    <p class="accepted-abstract">This paper presents a method to expand input vocabulary for smartphones. To this end, our method uses index finger gestures on and above the back of the smartphone. The input vocabulary of our method is according to index finger gestures such as touching and bending/stretching. To enable the detection of these gestures, we built a system composed of the smartphone and ring-like device. In pilot studies using our system, the touching the BoD was detected with an accuracy of 94.3% on average.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#122</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">A Self-Sensing Technique Using Inductively-Coupled Coils for Deformable User Interfaces</span>
                    <p class="accepted-authors">Junichiro Kadomoto, Hidetsugu Irie, and Shuichi Sakai (The University of Tokyo)</p>
                    <p class="accepted-abstract">We present a device shape sensing method using coils that are inductively coupled in the horizontal direction. By observing the change in the coupling characteristics between the coils arranged side by side, the positional relationship between the coils can be detected. By using the proposed technique, the shape of an object having a coil can be sensed without an external sensing mechanism such as a camera. In this paper, we show two types of prototypes, a rigid device combining multiple small tiles and a flexible device, and verify the basic characteristics. By utilizing the proposed technique, a deformable user interface with various inputs can be constructed simply by forming simple metal wiring on the device.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#127</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Gaze-Based Self-Confidence Estimation on Multiple-Choice Questions and Its Feedback</span>
                    <p class="accepted-authors">Shoya Ishimaru (German Research Center for Artificial Intelligence (DFKI)); Takanori Maruichi and Koichi Kise (Osaka Prefecture University); Andreas Dengel (German Research Center for Artificial Intelligence (DFKI))</p>
                    <p class="accepted-abstract">Self-confidence -- an assurance of one's personal decision and ability -- is one of the most important factors in learning. When there is a gap between a learner's confidence and comprehension, the learner loses a chance to review a learning subject correctly. To solve this problem, we propose a system which estimates self-confidence while solving multiple-choice questions by eye tracking and gives feedback about which question should be reviewed carefully. The system was evaluated in our experiment involving 20 participants. We observed that correct answer rates of questions were increased by 14% and 17% by giving feedback about correct answers without confidence and incorrect answers with confidence, respectively.</p>
                </div>
            </li>
            
        
            <h3>Localized Studies</h3>
            
            <li class="accepted-submission">
                <div class="accepted-id">#44</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Design of Alert App and related Device for Hearing Impaired Users in India and Afghanistan</span>
                    <p class="accepted-authors">Ganesh (Bhutkar)</p>
                    <p class="accepted-abstract">Sounds are important pressure waves which keep us informed about the events around us. Most of these sounds such as the ringing of the phone, crying of a baby, doorbell, fire alarm, etc. are vital for us in the day to day life. People with hearing impairment have difficulties in recognition of these sounds. This paper discusses a paper prototype design of Alert Device and Smartphone Application for hearing impaired users. The prototype design of both Alert Device and Smartphone Applicaion is designed based on a detailed literature survey as well as peer Android application review. The prototype device design includes several important features such as detection of doorbell, crying of a baby, fire alarm, motion detection alarm, phone ringing, self-training of sound, SOS/Panic button, and sound log. This device provides alert information on the smartphone, tablet, and smartwatch. In the future, this alert information can also be provided on TV, lamps, flashing lights and other devices.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#45</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Kotha Bondhu: Translating Sign Languages into Bengali Voice</span>
                    <p class="accepted-authors">Mahabub Hossain, Abdullah Mahmood, Md. Rajoan Rahman, Sohanur Rahman, Rahat Jahangir Rony, and Nova Ahmed (North South University)</p>
                    <p class="accepted-abstract">Sign languages are the only communication medium for mute and deaf people all over the world, but all the general people are not familiar with it. It is really tough for these people to make other people understand their voices. In the context of Bangladesh, we have studied these community people specifically from the Tablighi Jamaat community who use different sign language to communicate with people. By studying them we have gathered the local signs along with global standard sign languages in an application named Kotha Bondhu. It is a very simpler application that is understandable to any community people and is able to translate the sign languages into Bengali voice.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#48</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Challenges and Opportunities for Accessible Seoul Metropolitan Buses: An Interview Study of People with Visual Impairments</span>
                    <p class="accepted-authors">Subin Park and Gyeonghun Kim (Kyung Hee University); Hyunggu Jung (University of Seoul)</p>
                    <p class="accepted-abstract">Nowadays, a number of people with visual impairments (PVI) access public buses in the Seoul Metropolitan area. Existing studies reported the challenges faced by PVI when they use buses in multiple cities. Nevertheless, little is known about the accessibility issues of Seoul Metropolitan buses. To reduce the gap, we conducted semi-structured interviews with nine PVI to investigate the challenges and opportunities for accessible Seoul Metropolitan buses. We discovered ten challenges PVI faced when they use Seoul Metropolitan buses. Based on the identified challenges, we propose three opportunities for improving accessibility of the Seoul Metropolitan bus system.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#49</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">DigiMo - towards developing an emotional intelligent chatbot in Singapore</span>
                    <p class="accepted-authors">Andreea I. Niculescu and Ivan Kukanov (Institute for Infocomm Research, Singapore); Bimlesh Wadhwa (National University of Singapore, Singapore)</p>
                    <p class="accepted-abstract">The paper is a work in progress report on the development of DigiMo, a chatbot with emotional intelligence. The chatbot development is based on a data collection and annotations of real dialogues between local Singaporeans expressing genuine emotions. The models were trained with cakechat, an open source sequence-to-sequence deep neural network. Perplexity measurements from automatic testing as well as feedback from 6 expert evaluators confirmed the chatbot answers have high accuracy</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#61</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Localization and Globalization of Website Design: A pilot study focusing on comparison of government websites</span>
                    <p class="accepted-authors">mohamed adnan Shah (Universiti Teknologi Malaysia); Wong Chung Wei (Asia Pacific University Malaysia); Masitah Ghazali (Universiti Teknologi Malaysia)</p>
                    <p class="accepted-abstract">This research aims to explore the elements of designing user interfaces that are affected by the cultural diversity of users through a pilot study focusing on Arab and western government sites. The issues of localization and globalization of websites and effects of cultural diversity in design of the user-interfaces have been around for a while, but most of the studies focused on western, American and Southeast Asian and represented their perspectives in general. This study intends to identify differences in design features between the government websites for each of (UK, French, Iraq, UAE), and analyses how these features are affected by cultural diversity. The outcomes of this research can contribute as guidelines within a framework that takes into consideration in the Arabic website development, especially towards the development of e-government websites.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#74</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Finding &amp; Evaluating Community Policing Apps in Asia</span>
                    <p class="accepted-authors">Min Zhang, Arosha Bandara, and Blaine A. Price (The Open University); Bashar Nuseibeh (University of Limerick)</p>
                    <p class="accepted-abstract">The ubiquity of mobile devices creates new opportunities for the police to engage with citizens anywhere and anytime. However, there is limited academic work evaluating these technologies. This paper reports on a review study of Android community policing (CP) apps used in Asia. Our study indicates that in the absence of guidance, finding appropriate Asian CP apps is challenging. This paper reports the descriptive app Store characteristics, functionalities, communication channels, and privacy features of CP apps. We conclude with some design implications and call for developing a standardized app store description system and an evaluation model to help users find and select appropriate CP apps.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#78</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Study of Instructional Illustrations on ICTs: Considering persona of low-literate users form India</span>
                    <p class="accepted-authors">Rucha Tulaskar (Continuum Managed Services)</p>
                    <p class="accepted-abstract">Technology has the potential to improve the lives of underprivileged communities from developing regions of the world, especially those with low-literacy skills. Human-Computer Interaction (HCI) researchers have conducted studies to understand an effective way to communicate with this group using Information and Communication Technologies (ICTs). Beyond facilitating communication, ICTs have transformed the way low-literate users send money, learn skills and seek references, etc. As instructions (guidelines, rules, laws or warnings) play an important part while using these services on ICTs, finding effective ways to deliver those instructions has become crucial for HCI practitioners, as low-literate users face difficulties in using ICTs with only textual interfaces [1]. This study focusses on communicating these instructions through visual communication in the form of instructional illustrations. The study further investigates the effectiveness of 'Instructional Illustrations' using an educational mobile app and compares it with traditional instructional video communication with the low-literate group of Anganwadi workers in India.</p>
                </div>
            </li>
            
        
            <h3>Health and Self-Improvement</h3>
            
            <li class="accepted-submission">
                <div class="accepted-id">#1</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">BYE-TAL: Designing a Smartphone App for Sustainable SelfHealthcare through Design Thinking Process</span>
                    <p class="accepted-authors">Min Ji Kwon and Jihyun Lee (Kyung Hee University); Wan Hae Lee and Hyunggu Jung (University of Seoul)</p>
                    <p class="accepted-abstract">It is not easy for people to consistently take care of their health without motivation. Existing smartphone apps have assisted with people managing their personal health, but there still remain questions whether target users' needs were addressed to support the users, we report on each stage of a design thinking process for redesigning experiences of people their 20s to 40s for managing their personal health. Outcomes from each stage of the design thinking process show that the process is applicable to other domains when people create a smartphone app to address the needs of their target users effectively.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#13</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Design Thinking for Developing a Case-based Reasoning Emotional Robot: In the Context of Interactive Interview</span>
                    <p class="accepted-authors">Sheng Ming Wang, Wen Che Yang, and Wei Min Cheng (Department of Interaction Design, National Taipei University of Technology)</p>
                    <p class="accepted-abstract">As the application of design and technology has become more interdisciplinary and integrated, the development of interactive service robots (ISRs), which are designed according to unique situational requirements, has emerged as a popular trend. Research has shown that if affective computing technologies and machine learning mechanisms can be introduced to enhance interaction and feedback between ISRs and users, ISRs may be better aligned with both the service scenarios and the future development of innovative services. Based on an interdisciplinary integration framework, this study combined the concept and methodologies  of design thinking, emotion detection technologies, and case-based reasoning (CBR), based on the  use case  of a simulated interview for empirical research, and developed a prototype emotion-sensing robot (ESR) system for the planning and testing of emotion sensing. Three emotion detection and analysis indicators, namely, happiness index of facial expressions, blink rate, and semantic emotions conveyed by the text on their resume, were proposed as the basis for analyzing emotional perception in this study. The experimental results were then used to analyze the effectiveness of the technologies as well as the value, utility, and affordance of the interactive interview bot  system.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#23</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">BeActive: Encouraging Physical Activities with Just-in-time Health Intervention and Micro Financial Incentives</span>
                    <p class="accepted-authors">Juho Sun, Sangkeun Park, and Yong Jeong (KAIST); Kyong-Mee Chung, Chang-Suk Lee, Hee-Won Kim, and Seo-Yeon Ahn (Yonsei University); Ahsan Khandoker and Leontios Hadjileontiadis (Khalifa University); Uichin Lee (KAIST)</p>
                    <p class="accepted-abstract">Encouraging patients with cardiovascular disease to be more active is one of the critical challenges in conventional rehabilitation programs. Rehabilitation programs are mostly offered at specific times and locations (e.g., clinical facilities or in-home exercise programs), which are the root causes of participation barriers. We envision that use of mobile and wearable technologies can overcome such spatial/temporal restrictions and offer novel opportunities for promoting physical activities in their everyday lives.  In this position paper, we introduce BeActive, a mobile-based intervention platform that delivers just-in-time intervention messages to help patients to be more active in their daily lives. The key innovation of BeActive is to leverage fine-grained tracking of user behaviors to deliver just-in-time feedback and to incentivize health behavior maintenance via micro financial rewards. To show the feasibility of BeActive, we conducted a preliminary study for seven days (n=5), and presented several design improvements for just-in-time health intervention.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#31</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Exercise Measurement using a Built-in Camera in a Mobile Device</span>
                    <p class="accepted-authors">Kaho Kato, Chengshuo Xia, and Yuta Sugiura (Keio University)</p>
                    <p class="accepted-abstract">Nowadays, as life expectancy increases, daily exercise have played a significant role for people to stay healthy. In this paper, we propose an exercise measurement system by a mobile device with a built-in camera. An application based on Unity for relevant exercise recording of a user is developed. In a proposed application platform, the system can measure and classify multiple kinds of exercise using only a video of a human face. It can save the troubles of a user during the experience, and the user’s motivation for exercise is likely to be improved. When a user exercises in a condition the face is put within an angle of view of a camera, the system utilizes 30 feature points with two dimensions from a video of the face. Fast Fourier transform is applied to extract the features from obtained frame data and classification of related exercises is performed by support vector machine (SVM). Via the Evaluation experiment, the average classification accuracy of our system can reach up to 91.5%.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#54</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">A case study of food production using Artificial intelligence</span>
                    <p class="accepted-authors">Takuya Sera, Sayaka Izukura, Izumi Hashimoto, and Takashi Motegi (NEC corporation); Yosuke Motohashi (NEC Corporation)</p>
                    <p class="accepted-abstract">In these days, artificial intelligence (AI) finds applications in many different domains, including art creation such as painting and music. However, there is lack of know-how involving AI in developing food products. In this case, we analyzed a large number of Japanese newspaper articles and developed a chocolate that represents the mood of each year. Specifically, the mood was expressed by predicting the taste of words by machine learning. This paper describes how to create software that converts human sensation into taste, and how people develop products based on it, and how to evaluate the resulting product. In the result, we introduce a product developed with the support of artificial intelligence that has an effect of stimulating curiosity in consumers and can lead developers to new discoveries and perspectives. In the future, we aim to create a system that supports collaborative recipe development involving AI, developers, and consumers.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#65</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Development of a Low Cost Wearable with Mobile Sensing to Monitor Driving Stress through HRV</span>
                    <p class="accepted-authors">Rahat Jahangir Rony and Nova Ahmed (North South University)</p>
                    <p class="accepted-abstract">Stress is a mental state that is responsible for changing human behavior. Driving stress is harmful because it may cause road accidents. In developing countries, the rate of road accidents is higher where driving stress is responsible very often. Today monitoring any stress by using wearable is a growing research area, but most of the commercially available wearables are expensive. Only a few wearables are developed to get specifically the driving stress in developed nations. We gradually develop a low-cost wearable associated with a mobile sensing application to detect the driving stress along with road conditions by analyzing HRV (Heart Rate Variability) in developing country context to support the low-income community.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#75</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">A Study of Wearable Accelerometers Layout for Human Activity Recognition</span>
                    <p class="accepted-authors">Chengshuo Xia and Yuta Sugiura (Keio University)</p>
                    <p class="accepted-abstract">For  devices of human daily activity detection, accelerometer, can sense acceleration signals with different characteristics according to different parts of the human body. In this paper, we present a framework to investigate the impact of the number and placement of accelerometers on human daily activity recognition. 17 different parts of body are equipped with accelerometers, and examined. Multistage and multiswarm discrete particle swarm optimization (MSMS-DSPO) algorithm is developed to search the optimal sensor combinations on basis of number of sensor's demand. Additionally, user preferences of wearable sensor wearing is investigated and the motion recognition of involved place is analyzed as well. Thus, different sensor layouts for specific activity category recognition are provided, which is beneficial for user to arrange the devices on their body according to number requirement, activity type, preference or physical condition in an activity recognition application.</p>
                </div>
            </li>
            
        
            <h3>Communities and Societies</h3>
            
            <li class="accepted-submission">
                <div class="accepted-id">#76</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Analyzing Bias of Comments on Political News Articles to Facilitate Transparent Online Communities</span>
                    <p class="accepted-authors">Joon Ho Gwon (University of Seoul); Minji Kwon (Kyung Hee University); Hyunggu Jung (University of Seoul)</p>
                    <p class="accepted-abstract">Comments on news articles can affect people's perceptions and behaviors. Especially, comments from political articles on the Internet can have a significant impact on potential elections. Nevertheless, little is known about how people determine the degree of bias (DoB) of comments on news articles. To address such bias issues, current platforms of news articles offer criteria to sort multiple comments on news articles. However, little is known about whether the DoB of comments is reduced when publishers offer various criteria for sorting comments. We conducted surveys to identify how people determine DoB of comments on news article, and how bias varies depending on how comments are sorted. As a result, there was a significant difference among the DoB by comments. Our final goal is to develop an algorithm that generates unbiased comments from existing comments of internet articles and DoB of them.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#80</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Uncovering CHI Reviewers Needs and Barriers</span>
                    <p class="accepted-authors">Wan Hae Lee (University of Seoul); Min Ji Kwon (Kyung Hee University); Yewon Hyun (POSTECH); Jihyun Lee (Kyung Hee University); Joon Ho Gwon and Hyunggu Jung (University of Seoul)</p>
                    <p class="accepted-abstract">The peer-review process is an essential part of the CHI conference. In order to improve the peer-review process, assisting tools are being developed to help reviewers. However, there are only a few studies about reviewers’ perspectives regarding their tasks during the peer-review process. In this paper, we conducted semi-structured interviews with CHI reviewers who have experienced in reviewing paper submitted to the CHI conferences. As a result, we better understand how reviewing tasks are done differently by purposes, which tasks reviewers felt most challenging, and reviewers’ needs for better peer-review experiences.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#82</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">From Access to Effective Use: Open Data Portals for Everyday Citizens</span>
                    <p class="accepted-authors">Unisse C. Chua, Kyle L. Santiago, Ian Benedict M. Ona, Romeo Manuel N. Peña, Geremiah Zachary S. Marasigan, and Paolo Gabriel A. Delos Reyes (De La Salle University); Briane Paul V. Samson (Future University Hakodate, De La Salle University)</p>
                    <p class="accepted-abstract">Open government data allows for transparency from governments and access to data collected about its citizens. However, we are still far from achieving universal citizen participation because data literacy and experience are necessary to extract insights from data. There is also no guarantee if available data can address people's information needs. We explored the potential of open government data portals in addressing the information needs of citizens through an online survey and found that these can only be partially answered by the available data. To understand their information seeking behavior, we conducted usability tests of open data portals with 21 citizens, and used semi-structured interviews to identify gaps in the portals' design. We found that citizens would benefit from: localized and advanced search engines; and visualized, contextualized, and processed content for better sensemaking. We conclude with design guidelines for open data portals catered to citizens.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#84</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">CodeRhythm: A Tangible Programming Toolkit for Visually Impaired Students</span>
                    <p class="accepted-authors">Zhiyi Rong, Ngo Fung Chan, Taizhou Chen, and Kening Zhu (City University of Hong Kong)</p>
                    <p class="accepted-abstract">Block-based programming toolkits are widely used to nurture computational literacy in the young generation. However, they may not be suitable for young blind and visually impaired (BVI) students as these toolkits mostly rely on visual cues in the whole manipulation process. We present CodeRhythm, a tangible programming toolkit for engaging BVI users to learn basic programming concepts by creating simple melodies.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#93</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Writing Behavior as an Estimator of Self-Confidence on English Spelling Questions</span>
                    <p class="accepted-authors">Takanori Maruichi and Koichi Kise (Osaka Prefecture University)</p>
                    <p class="accepted-abstract">Reviewing plays an important role in the learning process of humans. A user's self-confidence is as important as the correctness of the answer to distinguish what to review. Giving feedback based on self-confidence enables learners to improve the quality of the review. Since it is still a familiar way for many students to write by hand, we propose a self-confidence estimation method based on handwriting behavior. To evaluate the performance of the proposed method, we employed the data collected while completing English spelling questions. The results revealed that the proposed method was able to predict self-confidence with 76% accuracy.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#95</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Challenges and Design Opportunities for Easy, Economical, and Accessible Offline Shoppers with Visual Impairments</span>
                    <p class="accepted-authors">Jihyun Lee and Jinsol Kim (Kyung Hee University); Hyunggu Jung (University of Seoul)</p>
                    <p class="accepted-abstract">Despite the numerous solutions offered, the offline shopping experience for people with visual impairments (PVI) does not seem to improve much. And we wanted to help PVI make convenient and economic shopping. Therefore, the goal of this research was to develop a system that helps PVI go offline shopping conveniently and economically. We conducted qualitative surveys and interviews with eight PVI. Based on the identified challenges, we proposed opportunities for easy and economical offline shopping. We hope the findings of this study contributes to a deeper understanding of the offline shopping experiences of PVI.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#131</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">A Smiley Face Icon Creator for Evaluating Emotion with Children</span>
                    <p class="accepted-authors">Yudai Kawakami (Ritsumeikan University College of InformationScience and Engineering); Kohei Matsumura (Ritsumeikan University College of Information Science and Engineering); Naomi Iga (Ritsumeikan University Graduate School of Information Science and Engineering); Haruo Noma (Ritsumeikan University College of Information Science and Engineering)</p>
                    <p class="accepted-abstract">In order to design an interactive system for children, it is imperative to hear the opinions and emotions of children them- selves. However, it is challenging to investigate their emotions because of their limited abilities of expression. They are in development in literacy and communication skill. The smiley face Likert scale is a survey method that utilizes face icons to express children’s emotion regardless of their literacy. How- ever, the method typically uses five to seven face icons for a survey. The number of face icons in the survey restricts measuring children’s emotions in detail. This paper proposes a novel survey method that introduces the visual analog scale into the smiley face Likert scale. We developed a tool that al- lows children to change the styles of the eyebrows and mouth continuously. Our method allows investigators to understand their emotions in detail. Through our preliminary study, we confirmed that children could express emotion using our face icons to a similar extent to that of adults.</p>
                </div>
            </li>
            
        
            <h3>Showcase</h3>
            
            <li class="accepted-submission">
                <div class="accepted-id">#2</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Showcase</span>
                    
                    <span class="accepted-title">Are Two Heads Better than One? Exploring Two-Party Conversations for Car Navigation Voice Guidance</span>
                    <p class="accepted-authors">Briane Paul Samson (Future University Hakodate, De La Salle University); Yasuyuki Sumi (Future University Hakodate)</p>
                    <p class="accepted-abstract">Voice guidance for car navigation typically considers drivers as docile actors. Recent works highlight limitations to this assumption which make drivers rely less on given directions. To explore how drivers can make better navigation decisions, we conducted a pilot Wizard-of-Oz study that gives turn suggestions in conversations between two voice agents. We asked 30 participants to drive in a simulation environment using voice guidance that gives three types of suggestions: familiar, optimal, and new routes. We examined their route choices, perceived workload and utterances while driving. We found that while most drivers followed directions appropriate for the given scenarios, they were more likely to make inappropriate choices after hearing alternatives in conversations. On the other hand, two-party conversations allowed drivers to better reflect on their choices after trips. We conclude by discussing preliminary design implications for car navigation voice guidance specifically and recommender systems in general.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#20</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Showcase</span>
                    
                    <span class="accepted-title">Crowdsourcing in China: Exploring the Work Experiences of Solo Crowdworkers and Crowdfarm Workers</span>
                    <p class="accepted-authors">Yihong Wang (Xi'an Jiaotong-Liverpool University); Konstantinos Papangelis (Rochester Institute of Technology); Michael Saker (City, University London); Ioanna Lykourentzou (Utrecht University); Alan Chamberlain (Univerity of Nottingham); Vassilis-Javed Khan (Eindhoven University of Technology)</p>
                    <p class="accepted-abstract">Recent research highlights the potential of crowdsourcing in China. Yet very few studies explore the workplace context and experiences of Chinese crowdworkers. Those that do, focus mainly on the work experiences of solo crowdworkers but do not deal with issues pertaining to the substantial amount of people working in ‘crowdfarms’. This article addresses this gap as one of its primary concerns. Drawing on a study that involves 48 participants, our research explores, compares and contrasts the work experiences of solo crowdworkers to those of crowdfarm workers. Our findings illustrate that the work experiences and context of the solo workers and crowdfarm workers are substantially different, with regards to their motivations, the ways they engage with crowdsourcing, the tasks they work on, and the crowdsourcing platforms they utilize. Overall, our study contributes to furthering the understandings on the work experiences of crowdworkers in China.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#43</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Showcase</span>
                    
                    <span class="accepted-title">FoodFab: Creating Food Perception Illusions using Food 3D Printing</span>
                    <p class="accepted-authors">Parinya Punpongsanon and Ying-Ju Lin (Osaka University); Xin Wen (MIT CSAIL); Daisuke Iwai and Kosuke Sato (Osaka University); Marianna Obrist (University of Sussex); Stefanie Mueller (MIT CSAIL)</p>
                    <p class="accepted-abstract">Food 3D printing enables the creation of customized food structures based on a person’s individual needs. In this paper, we explore the use of food 3D printing to create perceptual illusions for controlling the level of perceived satiety given a defined amount of calories. We present FoodFab, a system that allows users to control their food intake through modifying a food’s internal structure via two 3D printing parameters: infill pattern and infill density. In two experiments with a total of 30 participants, we studied the effect of these parameters on users’ chewing time that is known to affect people’s feeling of satiety. Our results show that we can indeed modify the chewing time by varying infill pattern and density, and thus control perceived satiety. Based on the results, we propose two computational models and integrate them into a user interface that simplifies the creation of personalized food structures.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#66</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Showcase</span>
                    
                    <span class="accepted-title">The Government's Dividend: Complex Perceptions of Social Media Misinformation in China</span>
                    <p class="accepted-authors">Zhicong Lu (University of Toronto); Yue Jiang (University of Maryland); Cheng Lu (University of Toronto); Mor Naaman (Cornell Tech); Daniel Wigdor (University of Toronto)</p>
                    <p class="accepted-abstract">The social media environment in China has become the dominant source of information and news over the past decade. This news environment has naturally suffered from challenges related to mis- and dis-information, encumbered by an increasingly complex landscape of factors and players including social media services, fact-checkers, censorship policies, and astroturfing. Interviews with 44 Chinese WeChat users were conducted to understand how individuals perceive misinformation and how it impacts their news consumption practices. Overall, this work exposes the diverse attitudes and coping strategies that Chinese users employ in complex social media environments. Due to the complex nature of censorship in China and participants’ lack of understanding of censorship, they expressed varied opinions about its influence on the credibility of online information sources. Further, although most participants claimed that their opinions would not be easily swayed by astroturfers, many admitted that they could not effectively distinguish astroturfers from ordinary Internet users. Participants’ inability to make sense of comments found online lead many participants to hold pro-censorship attitudes: the Government’s Dividend.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#69</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Designing Grit: Discovering Features Towards Supporting Novice Programmer DevOps Integration</span>
                    <p class="accepted-authors">Tyrone Justin Sta Maria, Gavin Raine Dizon, Vince Anthony Esquivel, Jordan Aiko Deja, and Unisse Chua (De La Salle University)</p>
                    <p class="accepted-abstract">DevOps is usually an industry approach that is practiced by seasoned and experienced programmers and developers.  In most university settings especially in the Philippine context, DevOps is not usually part of the curriculum and in some cases are only introduced to learner programmers as an elective or as bonus material. We refer to these learners as novice program-mers as defined by [5].  Upon graduation, these developers transition into industry roles where they are expected to be familiar with DevOps practices [10]. In most cases, they are not prepared, and fortunately, a great number of them are given training before fully transitioning into their hired roles.  In this paper, we attempt to discover and design an intervention mechanism that can assist and prepare novice programmers to easily learn DevOps at an early stage.  We gathered data and insights from novice programmers and inquired into their pains and struggles in learning and practicing DevOps.  To help them in this process, we propose Grit, a prototype tool to support novice programmers in integrating DevOps. Features and insights provided affordances and coming up with a set of guidelines that cater to the needs of novice programmers.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#86</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Development of real-world sensor optimal placement support software</span>
                    <p class="accepted-authors">Ayane Saito (Keio University); Wataru Kawai (The University of Tokyo); Yuta Sugiura (Keio University)</p>
                    <p class="accepted-abstract">There have been many studies on gesture recognition and posture estimation by combining real-world sensors and machine learning. In such situations, it is important to consider the sensor layout because the measurement result varies depending on the layout, number of sensors, and motion to be measured. However, it takes time and effort to prototype devices multiple times to find a sensor layout that has high identification accuracy. In this study, we developed software that can simulate the optimal layout and number of real-world sensors. In this time, the software can treat distance-measuring sensors as real-world sensors, and the user places these sensors freely in the software. The software measures the distance between the sensors and a mesh created from measurements of real-world deformation recorded by a Kinect device. We identified facial expressions using the distance data acquired by using the software. We simulated the optimal sensor placement for each number of sensors by increasing the number of sensors used for identification one by one in the software.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#94</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Video Lifelog Retrieval System for Ambiguous Search Queries</span>
                    <p class="accepted-authors">Mayo Morimoto, Masashi Fujitsuka, Sawako Mikami, and Yosuke Motohashi (NEC Corporation)</p>
                    <p class="accepted-abstract">The fifth-generation mobile network (5G) will soon become popular, and data utilization will increase. Although there is a large volume of video data, making it difficult to manage and use such data in our daily lives, there is huge potential with such data. We now often take photos using smartphones, but in future recording our lives by wearing video cameras would become popular. Since such data have a large amount of information, a video lifelog retrieval system is necessary. Although many studies on video retrieval have been conducted on some domains, e.g. TV programs, movies and so on, there have been few conducted on lifelogs. One of the main differences between them is regarding user queries and the fact that our memories are often ambiguous. We propose a video lifelog retrieval system that takes advantage of ambiguous search queries. We discuss the effectiveness of our system from our evaluation involving our own lifelog data we collected. We also discuss the characteristics of lifelog data and problems of our system.</p>
                </div>
            </li>
            
            <li class="accepted-submission">
                <div class="accepted-id">#149</div>
                <div class="accepted-details">
                    
                    <span class="accepted-type">Original Work</span>
                    
                    <span class="accepted-title">Leveraging Error Correction in Voice-based Text Entry by Talk-and-Gaze</span>
                    <p class="accepted-authors">Korok Sengupta and Sabin Bhattarai (University of Koblenz-Landau); Sayan Sarcar (University of Tsukuba); I Scott MacKenzie (York University); Steffen Staab (Universität Stuttgart &amp; University of Southampton)</p>
                    <p class="accepted-abstract">We present the design and evaluation of Talk-and-Gaze (TaG), a method for selecting and correcting errors with voice and gaze. TaG uses eye gaze to overcome the inability of voice-only systems to provide spatial information. The user’s point of gaze is used to select an erroneous word either by dwelling on the word for 800 ms (D-TaG) or by uttering a “select” voice command (V-TaG). A user study with 12 participants compared D-TaG, V-TaG, and a voice-only method for selecting and correcting words. Corrections were performed more than 20% faster with D-TaG compared to the V-TaG or voice-only methods. As well, D-TaG was observed to require 24% less selection effort than V-TaG and 11% less selection effort than voice-only error correction. D-TaG was well received in a subjective assessment with 66% of users choosing it as their preferred choice for error correction in voice-based text entry.</p>
                </div>
            </li>
            
        
    </ul>
    
</div>

  </div>

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">
    <h2 class="footer-heading">Showcasing Asian ingenuity in addressing local challenges in human-computer interaction research.</h2>

    <h2 class="footer-copyright"><p class="copyright">© 2020 &nbsp; <a href="https://asian-chi.github.io" target="_blank">Asian CHI Symposium</a> &nbsp; | &nbsp; <a href="https://acm.org" target="_blank">ACM</a> &nbsp; | &nbsp; <a href="https://sigchi.org" target="_blank">SIGCHI</a></p></h2>

  </div>

</footer>


  </body>

</html>
